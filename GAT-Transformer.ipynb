{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10865519,"sourceType":"datasetVersion","datasetId":6669520}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nfrom tqdm import tqdm\n\ndef impute_feature_array(feature_data, overall_mask, feature_name):\n    \"\"\"\n    Imputes NaN values in a feature array using spatial means for each time step.\n    Imputation is done only for pixels that are True in the overall_mask.\n\n    Args:\n        feature_data (np.array): The raw feature data (time, height, width).\n        overall_mask (np.array): A 2D boolean mask (height, width) where True indicates\n                                 pixels to be considered for mean calculation and imputation.\n        feature_name (str): Name of the feature for printing progress.\n\n    Returns:\n        np.array: The feature data with NaNs imputed within the masked areas.\n    \"\"\"\n    print(f\"Starting imputation for {feature_name}...\")\n    imputed_data = np.copy(feature_data) # Work on a copy\n    time_steps = feature_data.shape[0]\n\n    for t in tqdm(range(time_steps), desc=f\"Imputing {feature_name}\"):\n        current_slice = imputed_data[t] # Shape (height, width)\n        \n        # Extract values from the current slice only for pixels within the overall_mask\n        values_in_slice_for_mean_calc = current_slice[overall_mask]\n        \n        # Calculate the mean for imputation from these valid masked pixels\n        mean_for_imputation = np.nanmean(values_in_slice_for_mean_calc)\n        \n        # If the mean itself is NaN (e.g., all masked pixels in this slice were NaN), use 0.0\n        if np.isnan(mean_for_imputation):\n            mean_for_imputation = 0.0\n            # print(f\"Warning: All masked values were NaN for {feature_name} at timestep {t}. Using 0.0 for imputation.\")\n\n        # Identify NaN locations within the current_slice that are ALSO within the overall_mask\n        nan_locations_in_slice_to_impute = np.isnan(current_slice) & overall_mask\n        \n        # Apply imputation to these specific locations\n        current_slice[nan_locations_in_slice_to_impute] = mean_for_imputation\n        imputed_data[t] = current_slice\n        \n    print(f\"Imputation for {feature_name} complete.\")\n    return imputed_data\n\ndef main_offline_imputation(raw_data_path, output_data_path):\n    \"\"\"\n    Loads raw data, performs offline imputation for features, and saves the processed data.\n    \"\"\"\n    if not os.path.exists(raw_data_path):\n        print(f\"Error: Raw data file not found at {raw_data_path}\")\n        # Optionally, create dummy data for testing if needed\n        if not os.path.exists(\"dummy_raw_data.npz\"):\n            print(\"Creating dummy raw data for testing offline imputation...\")\n            T, H, W = 50, 10, 10 # Smaller for quick test\n            dummy_ndvi = np.random.rand(T, H, W) * 2 - 0.5 # Include negatives and >1 to test imputation\n            dummy_sm = np.random.rand(T, H, W)\n            dummy_lst = np.random.rand(T, H, W) * 50 + 273.15 # Temperature range\n            dummy_spi = np.random.randn(T, H, W) * 2\n            \n            # Introduce NaNs into features and SPI\n            for arr in [dummy_ndvi, dummy_sm, dummy_lst, dummy_spi]:\n                nan_indices = np.random.choice([True, False], size=arr.shape, p=[0.1, 0.9]) # 10% NaNs\n                arr[nan_indices] = np.nan\n            \n            # Ensure mask has some False areas if SPI is all NaN in some columns/rows for testing mask logic\n            dummy_spi[:, 0, :] = np.nan # Example: make first row of pixels always NaN in SPI\n\n            np.savez_compressed(\"dummy_raw_data.npz\", NDVI=dummy_ndvi, SoilMoisture=dummy_sm, LST=dummy_lst, SPI=dummy_spi)\n            raw_data_path = \"dummy_raw_data.npz\"\n            print(f\"Using dummy raw data from {raw_data_path}\")\n        else:\n            raw_data_path = \"dummy_raw_data.npz\"\n            print(f\"Using existing dummy raw data from {raw_data_path}\")\n\n\n    print(f\"Loading raw data from: {raw_data_path}\")\n    data = np.load(raw_data_path)\n\n    original_ndvi = data['NDVI']\n    original_sm = data['SoilMoisture']\n    original_lst = data['LST']\n    original_spi = data['SPI'] # SPI (target) is not imputed here, kept as is.\n\n    print(\"Original data shapes:\")\n    print(f\"NDVI: {original_ndvi.shape}\")\n    print(f\"SoilMoisture: {original_sm.shape}\")\n    print(f\"LST: {original_lst.shape}\")\n    print(f\"SPI: {original_spi.shape}\")\n\n    # Define the overall_mask based on SPI (pixels that are NOT NaN for ALL timesteps in SPI)\n    # This is the mask your model scripts generally use to define valid pixels for analysis.\n    overall_mask = ~np.isnan(original_spi).all(axis=0)\n    print(f\"Overall mask shape: {overall_mask.shape}, Total valid pixels in mask: {np.sum(overall_mask)}\")\n\n    if np.sum(overall_mask) == 0:\n        print(\"Error: The overall mask has no valid pixels. Check your SPI data or mask definition.\")\n        return\n\n    # Perform imputation\n    imputed_ndvi = impute_feature_array(original_ndvi, overall_mask, \"NDVI\")\n    imputed_sm = impute_feature_array(original_sm, overall_mask, \"SoilMoisture\")\n    imputed_lst = impute_feature_array(original_lst, overall_mask, \"LST\")\n\n    # Verify no NaNs in imputed features within the masked area\n    for feature_arr, name in zip([imputed_ndvi, imputed_sm, imputed_lst], [\"NDVI\", \"SM\", \"LST\"]):\n        has_nans_in_mask = np.isnan(feature_arr[:, overall_mask]).any()\n        print(f\"NaNs in imputed {name} (within mask): {has_nans_in_mask}\")\n        if has_nans_in_mask:\n            print(f\"Warning: Imputed {name} still contains NaNs within the masked area. Review imputation logic.\")\n\n    # Ensure the output directory exists\n    output_dir = os.path.dirname(output_data_path)\n    if output_dir and not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n        print(f\"Created output directory: {output_dir}\")\n\n    print(f\"Saving imputed data to: {output_data_path}\")\n    np.savez_compressed(\n        output_data_path,\n        NDVI_imputed=imputed_ndvi,\n        SoilMoisture_imputed=imputed_sm,\n        LST_imputed=imputed_lst,\n        SPI_original=original_spi, # Save original SPI\n        mask=overall_mask         # Save the mask used for imputation and future loading\n    )\n    print(\"Offline imputation complete. Processed data saved.\")\n\nif __name__ == '__main__':\n    # --- Configuration for the imputation script ---\n    # Replace with the actual path to your raw data file\n    # Example for full Gambia data based on your notebook:\n    RAW_DATA_NPZ_PATH = \"/kaggle/input/multivariate-time-series-12/time_series/Guinea-Bissau/Guinea-Bissau_combined.npz\"\n    \n    # Define where the imputed data will be saved\n    IMPUTED_DATA_NPZ_PATH = \"/kaggle/working/Guinea-Bissau_combined_imputed.npz\" # Saving in working directory\n\n    # Example for Wuli data (if you have a separate file for it)\n    # RAW_DATA_NPZ_PATH_WULI = \"/path/to/your/Wuli_combined_raw.npz\"\n    # IMPUTED_DATA_NPZ_PATH_WULI = \"/path/to/your/Wuli_combined_imputed.npz\"\n\n    main_offline_imputation(RAW_DATA_NPZ_PATH, IMPUTED_DATA_NPZ_PATH)\n    \n    # If you want to process another dataset like Wuli, call main_offline_imputation again:\n    # print(\"\\nProcessing Wuli data (example)...\")\n    # main_offline_imputation(RAW_DATA_NPZ_PATH_WULI, IMPUTED_DATA_NPZ_PATH_WULI)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:28:30.883642Z","iopub.execute_input":"2025-06-12T00:28:30.884539Z","iopub.status.idle":"2025-06-12T00:28:47.154793Z","shell.execute_reply.started":"2025-06-12T00:28:30.884455Z","shell.execute_reply":"2025-06-12T00:28:47.153886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nimport math\nimport joblib\n\n# --- Configuration ---\nMODEL_NAME = \"GAT_Transformer\" # Reflects the changes\nLOOKBACK = 24\nBATCH_SIZE = 128 \nLEARNING_RATE = 0.001\nNUM_EPOCHS = 70\nPATIENCE = 20\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# --- Updated load_and_preprocess_data for Sequence Models (from pre-imputed data) ---\ndef load_preprocessed_data_for_sequence(imputed_file_path, lookback_period):\n    print(f\"--- {MODEL_NAME}: Loading pre-imputed data from: {imputed_file_path} ---\")\n    data_imputed = np.load(imputed_file_path)\n    # These keys match your offline imputation script's output\n    ndvi_data = data_imputed['NDVI_imputed']\n    soil_moisture_data = data_imputed['SoilMoisture_imputed']\n    lst_data = data_imputed['LST_imputed']\n    spi_data = data_imputed['SPI_original'] # Original SPI for targets\n    mask = data_imputed['mask'] # The mask used during imputation\n\n    print(f\"Loaded imputed feature shapes: NDVI: {ndvi_data.shape}, SM: {soil_moisture_data.shape}, LST: {lst_data.shape}\")\n    print(f\"Loaded SPI_original shape: {spi_data.shape}, Mask shape: {mask.shape}, Valid pixels in mask: {np.sum(mask)}\")\n\n    time_steps, _, _ = ndvi_data.shape\n    X_list = []; y_list = []; valid_sample_indices_output = []\n    num_valid_pixels_in_mask = np.sum(mask)\n\n    # Pre-extract feature timeseries for valid pixels to make inner loop faster\n    ndvi_masked_ts = [ndvi_data[t][mask] for t in range(time_steps)]\n    lst_masked_ts = [lst_data[t][mask] for t in range(time_steps)]\n    sm_masked_ts = [soil_moisture_data[t][mask] for t in range(time_steps)]\n    spi_masked_ts = [spi_data[t][mask] for t in range(time_steps)] # For targets\n\n    for t in range(lookback_period, time_steps):\n        targets_for_current_t_step = spi_masked_ts[t]\n        \n        for pixel_idx_in_mask in range(num_valid_pixels_in_mask):\n            current_target_value = targets_for_current_t_step[pixel_idx_in_mask]\n            if np.isnan(current_target_value): continue # TARGET NaN REMOVAL\n\n            single_pixel_feature_sequence = []\n            for i in range(lookback_period):\n                time_index_in_original_data = t - lookback_period + i\n                val_ndvi = ndvi_masked_ts[time_index_in_original_data][pixel_idx_in_mask]\n                val_lst = lst_masked_ts[time_index_in_original_data][pixel_idx_in_mask]\n                val_sm = sm_masked_ts[time_index_in_original_data][pixel_idx_in_mask]\n                single_pixel_feature_sequence.append(np.array([val_ndvi, val_lst, val_sm]))\n            \n            X_list.append(np.array(single_pixel_feature_sequence))\n            y_list.append(current_target_value)\n            valid_sample_indices_output.append((t, pixel_idx_in_mask))\n            \n    X = np.array(X_list); y = np.array(y_list).reshape(-1, 1)\n    print(f\"Final X shape ({MODEL_NAME}): {X.shape}, y shape: {y.shape}, Valid samples: {len(valid_sample_indices_output)}\")\n    original_data_info = {'SPI': spi_data, 'NDVI': ndvi_data} \n    return X, y, mask, valid_sample_indices_output, original_data_info\n\n# --- Chronological Train-Test Split ---\ndef chronological_train_test_split(X, y, valid_sample_indices, test_ratio=0.2):\n    time_steps_of_samples = sorted(list(set([idx[0] for idx in valid_sample_indices])))\n    num_total_timesteps_with_samples = len(time_steps_of_samples)\n    num_test_timesteps = int(num_total_timesteps_with_samples * test_ratio)\n    if num_test_timesteps == 0 and num_total_timesteps_with_samples > 1: num_test_timesteps = 1\n    elif num_total_timesteps_with_samples <= 1: num_test_timesteps = 0\n    if num_test_timesteps == 0 or not time_steps_of_samples:\n        split_time_actual = time_steps_of_samples[-1] + 1 if time_steps_of_samples else 0\n    else:\n        split_time_actual = time_steps_of_samples[-num_test_timesteps]\n    train_indices = [i for i, (t, _) in enumerate(valid_sample_indices) if t < split_time_actual]\n    test_indices = [i for i, (t, _) in enumerate(valid_sample_indices) if t >= split_time_actual]\n    X_train = X[train_indices]; X_test = X[test_indices]; y_train = y[train_indices]; y_test = y[test_indices]\n    print(f\"X_train shape ({MODEL_NAME}): {X_train.shape}\"); print(f\"X_test shape ({MODEL_NAME}): {X_test.shape}\")\n    test_sample_indices_output = [valid_sample_indices[i] for i in test_indices]\n    return X_train, X_test, y_train, y_test, test_sample_indices_output\n\n# --- TimeSeriesDataset for GAT (Optimized Adjacency) ---\nclass TimeSeriesDatasetGAT(Dataset):\n    def __init__(self, features, targets, single_adj_matrix, scaler_X=None, scaler_y=None, is_train=True):\n        original_shape = features.shape\n        if is_train and scaler_X is None:\n            self.scaler_X = StandardScaler()\n            flattened = features.reshape(-1, original_shape[-1]); scaled = self.scaler_X.fit_transform(flattened)\n            self.features = scaled.reshape(original_shape)\n        elif not is_train and scaler_X is not None:\n            self.scaler_X = scaler_X\n            flattened = features.reshape(-1, original_shape[-1]); scaled = self.scaler_X.transform(flattened)\n            self.features = scaled.reshape(original_shape)\n        else: self.features = features; self.scaler_X = scaler_X\n        if is_train and scaler_y is None:\n            self.scaler_y = StandardScaler(); self.targets = self.scaler_y.fit_transform(targets)\n        elif not is_train and scaler_y is not None:\n            self.scaler_y = scaler_y; self.targets = self.scaler_y.transform(targets)\n        else: self.targets = targets; self.scaler_y = scaler_y\n        self.features = torch.tensor(self.features, dtype=torch.float32)\n        self.targets = torch.tensor(self.targets, dtype=torch.float32)\n        # Store the single, pre-computed adjacency matrix. Ensure it's a tensor.\n        if not isinstance(single_adj_matrix, torch.Tensor):\n            self.single_adj_matrix = torch.tensor(single_adj_matrix, dtype=torch.float32)\n        else:\n            self.single_adj_matrix = single_adj_matrix.to(dtype=torch.float32)\n\n    def __len__(self): return len(self.features)\n    def __getitem__(self, idx): return self.features[idx], self.single_adj_matrix, self.targets[idx]\n    def get_scalers(self): return self.scaler_X, self.scaler_y\n\n# --- Positional Encoding ---\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000): # max_len can be LOOKBACK + buffer\n        super(PositionalEncoding, self).__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term); pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0); self.register_buffer('pe', pe)\n    def forward(self, x): # x: (batch, seq_len, d_model)\n        # print(f\"DEBUG PositionalEncoding input x shape: {x.shape}\")\n        # print(f\"DEBUG PositionalEncoding self.pe original shape: {self.pe.shape}\")\n        # print(f\"DEBUG PositionalEncoding x.size(1) [for slicing pe's seq_len]: {x.size(1)}\")\n        pe_sliced = self.pe[:, :x.size(1)]\n        # print(f\"DEBUG PositionalEncoding self.pe_sliced shape: {pe_sliced.shape}\")\n        # print(f\"DEBUG Adding x ({x.shape}) and pe_sliced ({pe_sliced.shape})\")\n        try:\n            result = x + pe_sliced\n        except RuntimeError as e:\n            print(f\"ERROR during PositionalEncoding addition: x.shape={x.shape}, pe_sliced.shape={pe_sliced.shape}\")\n            raise e\n        return result\n\n\n# --- Graph Attention Layer & MultiHeadGraphAttention ---\nclass GraphAttentionLayer(nn.Module):\n    def __init__(self, in_features, out_features, dropout=0.2, alpha=0.2):\n        super(GraphAttentionLayer, self).__init__()\n        self.in_features=in_features; self.out_features=out_features; self.dropout_val=dropout; self.alpha=alpha\n        self.W=nn.Parameter(torch.empty(size=(in_features, out_features))); nn.init.xavier_uniform_(self.W.data, gain=1.414)\n        self.a=nn.Parameter(torch.empty(size=(2*out_features, 1))); nn.init.xavier_uniform_(self.a.data, gain=1.414)\n        self.leakyrelu=nn.LeakyReLU(self.alpha); self.dropout_layer=nn.Dropout(self.dropout_val)\n    def forward(self, h, adj): # h is (B, N, F_in), adj is (N,N) - single adj matrix passed from Dataset\n        Wh=torch.matmul(h, self.W); a_input=self._prepare_attention_input(Wh)\n        e=self.leakyrelu(torch.matmul(a_input, self.a).squeeze(-1))\n        # adj is (N,N), e is (B,N,N). Unsqueeze adj for broadcasting.\n        zero_vec = -9e15*torch.ones_like(e); attention_masked = torch.where(adj.unsqueeze(0) > 0, e, zero_vec)\n        attention_softmax=F.softmax(attention_masked, dim=-1); attention_dropout=self.dropout_layer(attention_softmax)\n        h_prime=torch.matmul(attention_dropout, Wh); return F.elu(h_prime)\n    def _prepare_attention_input(self, Wh):\n        B,N,_=Wh.size(); Wh_i=Wh.unsqueeze(2).expand(B,N,N,-1); Wh_j=Wh.unsqueeze(1).expand(B,N,N,-1)\n        return torch.cat([Wh_i, Wh_j], dim=-1)\n\nclass MultiHeadGraphAttention(nn.Module):\n    def __init__(self, in_features, out_features_per_head, n_heads, dropout=0.2, alpha=0.2, concat=True):\n        super(MultiHeadGraphAttention, self).__init__()\n        self.n_heads=n_heads; self.concat=concat\n        self.attentions=nn.ModuleList([GraphAttentionLayer(in_features, out_features_per_head, dropout, alpha) for _ in range(n_heads)])\n        self.out_dim = out_features_per_head * n_heads if concat else out_features_per_head\n    def forward(self, x, adj): # x is (B,N,F_in), adj is (N,N)\n        head_outputs=[att(x, adj) for att in self.attentions] # Each att will use the same adj\n        if self.concat: return torch.cat(head_outputs, dim=-1)\n        else: return torch.mean(torch.stack(head_outputs, dim=-1), dim=-1)\n\n# --- GAT+Transformer Model ---\nclass SpiPredictorGATTransformer(nn.Module):\n    def __init__(self, input_size, d_model_gat=64, gat_heads=4, \n                 d_model_transformer=64, transformer_heads=4, num_transformer_layers=2, \n                 dim_feedforward_transformer=256, dropout_rate=0.2): # Matched to presentation/log\n        super(SpiPredictorGATTransformer, self).__init__()\n        self.dropout_rate = dropout_rate\n        self.gat_input_proj = nn.Linear(input_size, d_model_gat) \n        self.gat_attention = MultiHeadGraphAttention(\n            in_features=d_model_gat, \n            out_features_per_head=d_model_gat // gat_heads, # Assumes divisibility\n            n_heads=gat_heads, dropout=dropout_rate, concat=True\n        )\n        gat_output_dim = self.gat_attention.out_dim\n        self.pos_encoder = PositionalEncoding(gat_output_dim, max_len=LOOKBACK + 10)\n        transformer_encoder_layer = nn.TransformerEncoderLayer(\n            d_model=gat_output_dim, nhead=transformer_heads, dim_feedforward=dim_feedforward_transformer,\n            dropout=dropout_rate, batch_first=True\n        )\n        self.transformer_encoder = nn.TransformerEncoder(transformer_encoder_layer, num_layers=num_transformer_layers)\n        # FC layers: 2 (64->32->1) from slides [cite: 1]\n        self.fc = nn.Sequential(\n            nn.Linear(gat_output_dim, 64), # Input is gat_output_dim (e.g. 64)\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(32, 1)\n        )\n    def forward(self, x, adj): # x: (B,L,F_in), adj: (L,L) - adj is NOT batched here\n        # print(f\"Model Input x shape: {x.shape}, adj shape: {adj.shape}\")\n        x_proj = F.elu(self.gat_input_proj(x))\n        # print(f\"After input_proj x_proj shape: {x_proj.shape}\")\n        x_gat_drop = F.dropout(x_proj, self.dropout_rate, training=self.training)\n        x_gat_attended = self.gat_attention(x_gat_drop, adj) # GAT layers will handle adj\n        # print(f\"After gat_attention x_gat_attended shape: {x_gat_attended.shape}\")\n        \n        # Ensure x_gat_attended is 3D (Batch, Seq, Feature) before PE\n        if x_gat_attended.dim() == 4 and x_gat_attended.shape[0] == 1 and x_gat_attended.shape[1] == BATCH_SIZE : # Heuristic for the previous error\n             print(f\"Warning: Reshaping x_gat_attended from {x_gat_attended.shape} to 3D\")\n             x_gat_attended = x_gat_attended.squeeze(0) # (BATCH_SIZE, Seq, Feature) - This is a guess if first dim is 1\n\n        x_pos_encoded = self.pos_encoder(x_gat_attended)\n        x_transformed = self.transformer_encoder(x_pos_encoded)\n        x_last_step = x_transformed[:, -1, :]\n        output = self.fc(x_last_step)\n        return output\n\n# --- Training Function for GAT-based models (handles single adjacency matrix) ---\ndef train_model_gat_based(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device, model_save_name):\n    best_val_loss = float('inf'); epochs_no_improve = 0\n    train_losses_history, val_losses_history = [], []\n    for epoch in range(num_epochs):\n        model.train(); epoch_train_loss = 0\n        for batch_X, batch_adj_single, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n            # batch_adj_single is the same for all samples in batch, already on correct device if pre-moved.\n            # Model's GAT layers expect adj to be (N,N) and handle broadcasting internally or it's passed (B,N,N) if collate_fn creates it.\n            # Current TimeSeriesDatasetGAT returns adj as (N,N). DataLoader makes it (B,N,N)\n            batch_X, batch_adj_single, batch_y = batch_X.to(device), batch_adj_single.to(device), batch_y.to(device)\n            outputs = model(batch_X, batch_adj_single[0]); # Pass only one adj matrix from the batch (they are all same)\n            loss = criterion(outputs, batch_y)\n            optimizer.zero_grad(); loss.backward(); optimizer.step(); epoch_train_loss += loss.item()\n        epoch_train_loss /= len(train_loader); train_losses_history.append(epoch_train_loss)\n        model.eval(); epoch_val_loss = 0\n        with torch.no_grad():\n            for batch_X, batch_adj_single, batch_y in val_loader:\n                batch_X, batch_adj_single, batch_y = batch_X.to(device), batch_adj_single.to(device), batch_y.to(device)\n                outputs = model(batch_X, batch_adj_single[0])\n                loss = criterion(outputs, batch_y); epoch_val_loss += loss.item()\n        epoch_val_loss /= len(val_loader); val_losses_history.append(epoch_val_loss)\n        print(f\"Epoch {epoch+1}: Train Loss={epoch_train_loss:.4f}, Val Loss={epoch_val_loss:.4f}\")\n        if epoch_val_loss < best_val_loss:\n            best_val_loss = epoch_val_loss; epochs_no_improve = 0; torch.save(model.state_dict(), model_save_name)\n        else: epochs_no_improve += 1\n        if epochs_no_improve >= patience: print(f\"Early stopping @ epoch {epoch+1}\"); break\n    if os.path.exists(model_save_name): model.load_state_dict(torch.load(model_save_name))\n    return model, train_losses_history, val_losses_history\n\n# --- Evaluation Function for GAT-based models ---\ndef evaluate_model_gat_based(model, test_loader, scaler_y, device, model_name=\"GAT-based Model\"):\n    model.eval(); all_preds_s, all_targets_s = [], []\n    with torch.no_grad():\n        for batch_X, batch_adj_single, batch_y_s in test_loader:\n            batch_X, batch_adj_single = batch_X.to(device), batch_adj_single.to(device)\n            outputs_s = model(batch_X, batch_adj_single[0]) # Pass one adj\n            all_preds_s.append(outputs_s.cpu().numpy()); all_targets_s.append(batch_y_s.numpy())\n    preds_s_np = np.vstack(all_preds_s); tgts_s_np = np.vstack(all_targets_s)\n    if scaler_y: preds_o = scaler_y.inverse_transform(preds_s_np); tgts_o = scaler_y.inverse_transform(tgts_s_np)\n    else: preds_o = preds_s_np; tgts_o = tgts_s_np\n    mse=mean_squared_error(tgts_o,preds_o); rmse=np.sqrt(mse); r2=r2_score(tgts_o,preds_o); mae=mean_absolute_error(tgts_o,preds_o)\n    print(f\"\\nEvaluation metrics ({model_name}):\\n MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n    return preds_o, tgts_o, mse, rmse, r2, mae\n\n# --- Plotting and Reconstruction (Definitions from Common Helper Functions section) ---\ndef plot_training_losses(train_losses, val_losses, model_name, save_dir='visualizations'):\n    if not os.path.exists(save_dir): os.makedirs(save_dir)\n    save_path = os.path.join(save_dir, f'training_losses_{model_name}.png')\n    plt.figure(figsize=(10, 6))\n    plt.plot(range(1, len(train_losses) + 1), train_losses, 'b-', label='Train Loss')\n    plt.plot(range(1, len(val_losses) + 1), val_losses, 'r-', label='Validation Loss')\n\n    # --- ADDED ANNOTATIONS ---\n    # Get the last epoch and loss values\n    last_epoch = len(train_losses)\n    last_train_loss = train_losses[-1]\n    last_val_loss = val_losses[-1]\n\n    # Add text annotation for the last training loss\n    plt.text(last_epoch, last_train_loss, f' {last_train_loss:.4f}', \n             color='blue', verticalalignment='center')\n\n    # Add text annotation for the last validation loss\n    plt.text(last_epoch, last_val_loss, f' {last_val_loss:.4f}', \n             color='red', verticalalignment='center')\n    # --- END OF ADDED CODE ---\n\n    # --- MODIFIED LINE from original code ---\n    # Set the y-axis to go from 0 to 0.3\n    plt.ylim(0, 0.3)\n\n    plt.xlabel('Epochs'); plt.ylabel('Loss (MSE)'); plt.title(f'Training & Validation Losses ({model_name})')\n    plt.legend(); plt.grid(True); plt.savefig(save_path); plt.show()\n\ndef plot_all_test_samples(targets_original, predictions_original, model_name, save_dir='visualizations'):\n    if not os.path.exists(save_dir): os.makedirs(save_dir)\n    save_path = os.path.join(save_dir, f'all_test_samples_{model_name}.png')\n    plt.figure(figsize=(12, 8)); plt.scatter(targets_original, predictions_original, alpha=0.3, color='blue', label='Samples')\n    min_val = min(targets_original.min(), predictions_original.min()); max_val = max(targets_original.max(), predictions_original.max())\n    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='y=x')\n    corr = np.nan\n    if len(targets_original.ravel()) > 1 and len(predictions_original.ravel()) > 1:\n        z = np.polyfit(targets_original.ravel(), predictions_original.ravel(), 1); p = np.poly1d(z)\n        sorted_targets = np.sort(targets_original.ravel())\n        plt.plot(sorted_targets, p(sorted_targets), 'g-', label=f'Regression: y={z[0]:.3f}x+{z[1]:.3f}')\n        corr = np.corrcoef(targets_original.ravel(), predictions_original.ravel())[0, 1]\n    plt.xlabel('True Values'); plt.ylabel('Predictions'); plt.title(f'Predictions vs True Values ({model_name}, r = {corr:.3f})')\n    plt.legend(); plt.grid(True)\n    mse = mean_squared_error(targets_original, predictions_original); rmse = np.sqrt(mse); mae = mean_absolute_error(targets_original, predictions_original); r2 = r2_score(targets_original, predictions_original)\n    stats_text = (f\"MSE: {mse:.4f}\\nRMSE: {rmse:.4f}\\nMAE: {mae:.4f}\\nR²: {r2:.4f}\\nCorr: {corr:.4f}\")\n    plt.figtext(0.15, 0.75, stats_text, bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'))\n    plt.tight_layout(rect=[0, 0, 1, 0.96]); plt.savefig(save_path); plt.show()\n\ndef reconstruct_rasters(predictions_flat, test_sample_indices, original_mask, spi_full_shape):\n    unique_test_time_indices_original = sorted(list(set([t for t, _ in test_sample_indices])))\n    reconstructed_spatial_rasters = np.full((len(unique_test_time_indices_original), spi_full_shape[1], spi_full_shape[2]), np.nan)\n    valid_pixel_row_coords, valid_pixel_col_coords = np.where(original_mask)\n    for i, (original_t, pixel_idx_in_mask) in enumerate(test_sample_indices):\n        relative_t_idx_in_reconstruction = unique_test_time_indices_original.index(original_t)\n        h_coord = valid_pixel_row_coords[pixel_idx_in_mask]; w_coord = valid_pixel_col_coords[pixel_idx_in_mask]\n        reconstructed_spatial_rasters[relative_t_idx_in_reconstruction, h_coord, w_coord] = predictions_flat[i][0]\n    return reconstructed_spatial_rasters, unique_test_time_indices_original\n\ndef visualize_raster_samples(real_rasters_for_test_timesteps, pred_rasters_for_test_timesteps, \n                             mask_for_visualization, unique_test_time_indices, model_name,\n                             num_samples_to_plot=5, output_dir='visualizations'):\n    if not os.path.exists(output_dir): os.makedirs(output_dir)\n    prefix = f'raster_sample_{model_name.lower()}'\n    colors = ['#730000', '#E60000', '#FFAA00', '#FCD37F', '#FFFF00', '#FFFFFF', '#DCF8FF', '#96D2FF', '#46A5FF', '#0000FF', '#000080']\n    cmap_usdm_spi = plt.cm.colors.LinearSegmentedColormap.from_list('usdm_spi', colors, N=256)\n    vmin_spi, vmax_spi = -3, 3\n    num_available_rasters = len(real_rasters_for_test_timesteps)\n    if num_available_rasters == 0: print(\"No rasters to visualize.\"); return\n    plot_indices = np.random.choice(num_available_rasters, min(num_samples_to_plot, num_available_rasters), replace=False)\n    for i, raster_idx_in_test_set in enumerate(plot_indices):\n        true_raster_slice = real_rasters_for_test_timesteps[raster_idx_in_test_set]\n        pred_raster_slice = pred_rasters_for_test_timesteps[raster_idx_in_test_set]\n        diff_raster_slice = np.full_like(true_raster_slice, np.nan)\n        valid_pixels_for_diff = ~np.isnan(true_raster_slice) & ~np.isnan(pred_raster_slice)\n        diff_raster_slice[valid_pixels_for_diff] = true_raster_slice[valid_pixels_for_diff] - pred_raster_slice[valid_pixels_for_diff]\n        diff_abs_max = np.nanmax(np.abs(diff_raster_slice)) if not np.all(np.isnan(diff_raster_slice)) else 1.0\n        fig, axes = plt.subplots(1, 3, figsize=(18, 6)); fig.suptitle(f'SPI Comparison ({model_name}) - Original Time Step: {unique_test_time_indices[raster_idx_in_test_set]}', fontsize=16)\n        ax1 = axes[0]; masked_true_spi = np.ma.array(true_raster_slice, mask=~mask_for_visualization); im1 = ax1.imshow(masked_true_spi, cmap=cmap_usdm_spi, vmin=vmin_spi, vmax=vmax_spi)\n        fig.colorbar(im1, ax=ax1, label='SPI Value', fraction=0.046, pad=0.04); ax1.set_title('True SPI'); ax1.axis('off')\n        ax2 = axes[1]; masked_pred_spi = np.ma.array(pred_raster_slice, mask=~mask_for_visualization); im2 = ax2.imshow(masked_pred_spi, cmap=cmap_usdm_spi, vmin=vmin_spi, vmax=vmax_spi)\n        fig.colorbar(im2, ax=ax2, label='SPI Value', fraction=0.046, pad=0.04); ax2.set_title('Predicted SPI'); ax2.axis('off')\n        ax3 = axes[2]; masked_diff_spi = np.ma.array(diff_raster_slice, mask=~mask_for_visualization); im3 = ax3.imshow(masked_diff_spi, cmap='RdBu_r', vmin=-diff_abs_max, vmax=diff_abs_max)\n        fig.colorbar(im3, ax=ax3, label='Difference (True - Predicted)', fraction=0.046, pad=0.04); ax3.set_title('Difference'); ax3.axis('off')\n        plt.tight_layout(rect=[0, 0, 1, 0.95]); save_filename = os.path.join(output_dir, f'{prefix}_time_{unique_test_time_indices[raster_idx_in_test_set]}.png')\n        plt.savefig(save_filename, dpi=200); plt.show()\n\n\n# --- Main Function (GAT+Transformer) ---\ndef main_gat_transformer():\n    print(f\"--- Running {MODEL_NAME} Model ---\")\n    print(f\"Using device: {DEVICE}\")\n    output_dir = f\"results_{MODEL_NAME.lower().replace('+', '_')}\" # Ensure '+' is filename-safe\n    viz_dir = os.path.join(output_dir, \"visualizations\")\n    if not os.path.exists(viz_dir): os.makedirs(viz_dir)\n\n    imputed_file_path = \"/kaggle/working/Guinea-Bissau_combined_imputed.npz\" # Adjust this path\n    # imputed_file_path = \"/kaggle/working/Guinea-Bissau_combined_imputed.npz\" # Or this for G-B\n\n    if not os.path.exists(imputed_file_path):\n        print(f\"ERROR: Pre-imputed data file not found at {imputed_file_path}. Please run the offline imputation script first.\")\n        print(\"Creating dummy pre-imputed data for workflow testing...\")\n        T, H, W = 50, 10, 10\n        dummy_ndvi_i = np.random.rand(T, H, W); dummy_sm_i = np.random.rand(T, H, W); dummy_lst_i = np.random.rand(T, H, W) + 273.15\n        dummy_spi_o = np.random.randn(T, H, W) * 2; dummy_spi_o[np.random.rand(T,H,W) < 0.05] = np.nan\n        dummy_mask_o = ~np.isnan(dummy_spi_o).all(axis=0); dummy_spi_o[:, ~dummy_mask_o] = np.nan\n        for arr in [dummy_ndvi_i, dummy_sm_i, dummy_lst_i]:\n            arr[:, ~dummy_mask_o] = np.nan\n            for t_idx in range(T):\n                 slice_masked = arr[t_idx][dummy_mask_o]; mean_val = np.nanmean(slice_masked)\n                 mean_val = 0.0 if np.isnan(mean_val) else mean_val\n                 nan_locs = np.isnan(arr[t_idx]) & dummy_mask_o; arr[t_idx][nan_locs] = mean_val\n        imputed_file_path = f\"dummy_imputed_data_{MODEL_NAME.lower().replace('+', '_')}.npz\"\n        np.savez_compressed(imputed_file_path, NDVI_imputed=dummy_ndvi_i, SoilMoisture_imputed=dummy_sm_i, LST_imputed=dummy_lst_i, SPI_original=dummy_spi_o, mask=dummy_mask_o)\n        print(f\"Using dummy pre-imputed data from {imputed_file_path}\")\n\n    X_all, y_all, data_mask, valid_idx_all, orig_data_info = load_preprocessed_data_for_sequence(imputed_file_path, LOOKBACK)\n    if X_all.shape[0] == 0: print(\"No valid samples. Exiting.\"); return\n    X_tv, X_test, y_tv, y_test, test_idx_list = chronological_train_test_split(X_all, y_all, valid_idx_all, test_ratio=0.2)\n    if X_tv.shape[0] == 0: print(f\"No training/validation samples for {MODEL_NAME}. Exiting.\"); return\n\n    # Create the single temporal adjacency matrix\n    adj_matrix_template = torch.zeros(LOOKBACK, LOOKBACK, dtype=torch.float32)\n    for i in range(LOOKBACK):\n        if i > 0: adj_matrix_template[i, i-1] = 1\n        if i < LOOKBACK - 1: adj_matrix_template[i, i+1] = 1\n        adj_matrix_template[i, i] = 1\n    adj_matrix_template = adj_matrix_template.to(DEVICE) # Move to device once if possible, or handle in DataLoader/loop\n    \n    tv_dataset = TimeSeriesDatasetGAT(X_tv, y_tv, adj_matrix_template.cpu(), is_train=True) # Dataset takes CPU tensor or numpy\n    scaler_X, scaler_y = tv_dataset.get_scalers()\n    test_loader = None\n    if X_test.shape[0] > 0:\n        test_dataset = TimeSeriesDatasetGAT(X_test, y_test, adj_matrix_template.cpu(), scaler_X, scaler_y, is_train=False)\n        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=(DEVICE.type=='cuda'))\n\n    train_s = int(0.8 * len(tv_dataset)); val_s = len(tv_dataset) - train_s\n    if val_s == 0 and train_s > 0: train_sub, val_sub = tv_dataset, tv_dataset\n    elif train_s == 0 or val_s == 0: print(\"Not enough data for train/val split. Exiting.\"); return\n    else: gen=torch.Generator().manual_seed(42); train_sub, val_sub = torch.utils.data.random_split(tv_dataset, [train_s, val_s], generator=gen)\n\n    train_loader = DataLoader(train_sub, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=(DEVICE.type=='cuda'))\n    val_loader = DataLoader(val_sub, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=(DEVICE.type=='cuda'))\n   \n    model_input_size = X_tv.shape[-1] \n    model = SpiPredictorGATTransformer(\n        input_size=model_input_size, d_model_gat=64, gat_heads=4, \n        d_model_transformer=64, transformer_heads=4, num_transformer_layers=2, \n        dim_feedforward_transformer=256, dropout_rate=0.2\n    ).to(DEVICE)\n    print(f\"\\n{MODEL_NAME} Model Architecture:\\n{model}\")\n    criterion = nn.MSELoss(); optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n   \n    model_save_path = os.path.join(output_dir, f\"best_spi_{MODEL_NAME.lower().replace('+', '_')}_model.pt\")\n    trained_model, train_L, val_L = train_model_gat_based(model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, PATIENCE, DEVICE, model_save_path)\n    plot_training_losses(train_L, val_L, MODEL_NAME, save_dir=viz_dir)\n   \n    if test_loader:\n        preds_o, tgts_o, mse, rmse, r2, mae = evaluate_model_gat_based(trained_model, test_loader, scaler_y, DEVICE, MODEL_NAME)\n        plot_all_test_samples(tgts_o, preds_o, MODEL_NAME, save_dir=viz_dir)\n        spi_shape_o = orig_data_info['SPI'].shape\n        recon_preds, unique_test_t = reconstruct_rasters(preds_o, test_idx_list, data_mask, spi_shape_o)\n        np.savez_compressed(os.path.join(output_dir, f'spi_{MODEL_NAME.lower().replace(\"+\", \"_\")}_predictions.npz'), predictions=recon_preds, mask=data_mask, time_steps=unique_test_t)\n        full_spi_original = np.load(imputed_file_path)['SPI_original']\n        true_test_rs = np.array([full_spi_original[t] for t in unique_test_t])\n        visualize_raster_samples(true_test_rs, recon_preds, data_mask, unique_test_t, MODEL_NAME, output_dir=viz_dir)\n    else: print(f\"Test set for {MODEL_NAME} was empty. Skipping final evaluation.\")\n\n    joblib.dump(scaler_X, os.path.join(output_dir, f\"scaler_X_{MODEL_NAME.lower().replace('+', '_')}.pkl\"))\n    joblib.dump(scaler_y, os.path.join(output_dir, f\"scaler_y_{MODEL_NAME.lower().replace('+', '_')}.pkl\"))\n    print(f\"{MODEL_NAME} model training complete. Results in {output_dir}\")\n\nif __name__ == \"__main__\":\n    main_gat_transformer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:28:47.156314Z","iopub.execute_input":"2025-06-12T00:28:47.156652Z"}},"outputs":[],"execution_count":null}]}