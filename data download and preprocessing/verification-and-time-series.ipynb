{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10390638,"sourceType":"datasetVersion","datasetId":6432912},{"sourceId":10597285,"sourceType":"datasetVersion","datasetId":6552971},{"sourceId":10624689,"sourceType":"datasetVersion","datasetId":6578382},{"sourceId":10705470,"sourceType":"datasetVersion","datasetId":6634755},{"sourceId":10740961,"sourceType":"datasetVersion","datasetId":6660533},{"sourceId":10743727,"sourceType":"datasetVersion","datasetId":6660536}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install rasterio matplotlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T01:08:00.263190Z","iopub.execute_input":"2025-02-27T01:08:00.263511Z","iopub.status.idle":"2025-02-27T01:08:07.654416Z","shell.execute_reply.started":"2025-02-27T01:08:00.263486Z","shell.execute_reply":"2025-02-27T01:08:07.653212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import rasterio\n# from rasterio.plot import show\n# import matplotlib.pyplot as plt\n# import numpy as np\n# from scipy.ndimage import binary_dilation\n\n\n# # Paths to the images\n# ndvi_path = \"/kaggle/input/ndvi-month/NDVI_Images/Gambia,_The/NDVI_Gambia,_The_2000_02.tif\"\n# soil_moisture_path = \"/kaggle/input/soil-moisture/soil_moisture_masked/Gambia_The/GLDAS_SoilMoisture_Gambia_The_2000_01.tif\"\n# spi_path = \"/kaggle/input/spi-chirps/Gambia,_The/Gambia,_The_SPI_2000_01.tif\"\n# lst_path = \"/kaggle/input/lst-22/EarthEngineExports/Gambia,_The/LST_Gambia,_The_2000_02.tif\"\n\n# # Load the images\n# def load_image(path, band=1):\n#     with rasterio.open(path) as src:\n#         return src.read(band), src.transform, src.crs, src.shape\n\n# # Load NDVI\n# ndvi_data, ndvi_transform, ndvi_crs, ndvi_shape = load_image(ndvi_path)\n\n# # Load Soil Moisture (Band 1: Data, Band 2: Mask)\n# soil_moisture_data, soil_moisture_transform, soil_moisture_crs, soil_moisture_shape = load_image(soil_moisture_path, band=1)\n# soil_moisture_mask, _, _, _ = load_image(soil_moisture_path, band=2)\n\n# # Load SPI\n# spi_data, spi_transform, spi_crs, spi_shape = load_image(spi_path)\n\n# # Load LST\n# lst_data, lst_transform, lst_crs, lst_shape = load_image(lst_path)\n\n# # Buffer the mask to cover edge pixels\n# buffered_mask = binary_dilation(soil_moisture_mask, iterations=1)\n\n# # Check spatial alignment\n# def check_alignment(transform1, transform2, crs1, crs2, shape1, shape2, name1, name2):\n#     if transform1 != transform2:\n#         print(f\"Transform mismatch between {name1} and {name2}.\")\n#     if crs1 != crs2:\n#         print(f\"CRS mismatch between {name1} and {name2}.\")\n#     if shape1 != shape2:\n#         print(f\"Shape mismatch between {name1} and {name2}.\")\n#     if transform1 == transform2 and crs1 == crs2 and shape1 == shape2:\n#         print(f\"{name1} and {name2} are aligned.\")\n\n# # Compare NDVI with Soil Moisture\n# check_alignment(ndvi_transform, soil_moisture_transform, ndvi_crs, soil_moisture_crs, ndvi_shape, soil_moisture_shape, \"NDVI\", \"Soil Moisture\")\n\n# # Compare NDVI with SPI\n# check_alignment(ndvi_transform, spi_transform, ndvi_crs, spi_crs, ndvi_shape, spi_shape, \"NDVI\", \"SPI\")\n\n# # Compare NDVI with LST\n# check_alignment(ndvi_transform, lst_transform, ndvi_crs, lst_crs, ndvi_shape, lst_shape, \"NDVI\", \"LST\")\n\n# def verify_mask(data, mask, dataset_name, no_data_value=0):\n#     valid_pixels = mask == 255  # Assuming mask uses 255 for valid pixels\n#     data_outside_mask = data[~valid_pixels]  # Data outside the mask\n#     data_inside_mask = data[valid_pixels]   # Data inside the mask\n\n#     # Check if there are any non-NaN, non-zero values outside the mask\n#     if dataset_name in [\"NDVI\", \"SPI\", \"LST\"]:\n#         valid_data_outside_mask = data_outside_mask[~np.isnan(data_outside_mask) & (data_outside_mask != no_data_value)]\n#     else:\n#         valid_data_outside_mask = data_outside_mask[~np.isnan(data_outside_mask)]\n\n#     if len(valid_data_outside_mask) > 0:\n#         print(f\"Warning: {dataset_name} has valid data outside the mask.\")\n#         # Clip the data to the mask\n#         if dataset_name in [\"NDVI\", \"SPI\", \"LST\"]:\n#             data[~valid_pixels] = np.nan  # Set to 0 (No-Data) outside the mask\n#         else:\n#             data[~valid_pixels] = np.nan  # Set to NaN outside the mask\n#         print(f\"Clipped {dataset_name} data to the mask.\")\n#     else:\n#         print(f\"{dataset_name}: All valid data is inside the mask.\")\n\n#     # Check if there are any NaN values inside the mask\n#     if np.any(np.isnan(data_inside_mask)):\n#         print(f\"Warning: {dataset_name} has NaN values inside the mask.\")\n#     else:\n#         print(f\"{dataset_name}: No NaN values inside the mask.\")\n# # Verify NDVI\n# verify_mask(ndvi_data, soil_moisture_mask, \"NDVI\")\n\n# # Verify Soil Moisture\n# verify_mask(soil_moisture_data, soil_moisture_mask, \"Soil Moisture\")\n\n# # Verify SPI\n# verify_mask(spi_data, soil_moisture_mask, \"SPI\")\n\n# # Verify LST\n# verify_mask(lst_data, soil_moisture_mask, \"LST\")\n\n# # Visualize the data and mask\n# def plot_data_and_mask(data, mask, title):\n#     plt.figure(figsize=(12, 6))\n#     plt.subplot(1, 2, 1)\n#     plt.imshow(data, cmap='viridis', vmin=np.nanmin(data), vmax=np.nanmax(data))\n#     plt.colorbar(label='Value')\n#     plt.title(f\"{title} Data\")\n\n#     plt.subplot(1, 2, 2)\n#     plt.imshow(mask, cmap='gray')\n#     plt.colorbar(label='Mask (1=Valid)')\n#     plt.title(f\"{title} Mask\")\n#     plt.show()\n\n# # Plot NDVI\n# plot_data_and_mask(ndvi_data, soil_moisture_mask, \"NDVI\")\n\n# # Plot Soil Moisture\n# plot_data_and_mask(soil_moisture_data, soil_moisture_mask, \"Soil Moisture\")\n\n# # Plot SPI\n# plot_data_and_mask(spi_data, soil_moisture_mask, \"SPI\")\n\n# # Plot LST\n# plot_data_and_mask(lst_data, soil_moisture_mask, \"LST\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T00:06:08.926276Z","iopub.execute_input":"2025-02-27T00:06:08.926699Z","iopub.status.idle":"2025-02-27T00:06:10.974081Z","shell.execute_reply.started":"2025-02-27T00:06:08.926667Z","shell.execute_reply":"2025-02-27T00:06:10.972947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import rasterio\n# import numpy as np\n# import matplotlib.pyplot as plt\n# # Path to the soil moisture image\n# image_path = \"/kaggle/input/soil-moisture/soil_moisture_masked/Gambia_The/GLDAS_SoilMoisture_Gambia_The_2000_01.tif\"\n\n# def test_nan_values(image_path):\n#     \"\"\"Test for NaN values in Band 1 of the soil moisture image.\"\"\"\n#     # Open the image\n#     with rasterio.open(image_path) as src:\n#         # Read Band 1 (soil moisture data)\n#         band1 = src.read(1)\n\n#         # Check for NaN values\n#         nan_count = np.isnan(band1).sum()\n#         total_pixels = band1.size\n#         nan_percentage = (nan_count / total_pixels) * 100\n\n#         # Print results\n#         print(f\"Testing NaN values in Band 1 of {image_path}:\")\n#         print(f\"Total pixels: {total_pixels}\")\n#         print(f\"NaN values: {nan_count}\")\n#         print(f\"Percentage of NaN values: {nan_percentage:.2f}%\")\n\n# # Test the image\n# test_nan_values(image_path)\n# def visualize_bands(image_path):\n#     \"\"\"Visualize Band 1 (soil moisture) and Band 2 (mask).\"\"\"\n#     with rasterio.open(image_path) as src:\n#         # Read Band 1 (soil moisture data)\n#         band1 = src.read(1)\n\n#         # Read Band 2 (mask)\n#         band2 = src.read(2)\n\n#         # Plot Band 1\n#         plt.figure(figsize=(10, 5))\n#         plt.subplot(1, 2, 1)\n#         plt.imshow(band1, cmap=\"viridis\", vmin=0, vmax=100)\n#         plt.colorbar(label=\"Soil Moisture\")\n#         plt.title(\"Band 1: Soil Moisture\")\n\n#         # Plot Band 2\n#         plt.subplot(1, 2, 2)\n#         plt.imshow(band2, cmap=\"binary\", vmin=0, vmax=1)\n#         plt.colorbar(label=\"Mask (1 = Inside Country, 0 = Outside)\")\n#         plt.title(\"Band 2: Mask\")\n\n#         plt.tight_layout()\n#         plt.show()\n\n# # Visualize the bands\n# visualize_bands(image_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T05:15:43.684491Z","iopub.execute_input":"2025-02-26T05:15:43.684894Z","iopub.status.idle":"2025-02-26T05:15:44.341508Z","shell.execute_reply.started":"2025-02-26T05:15:43.684857Z","shell.execute_reply":"2025-02-26T05:15:44.340234Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import rasterio\n\n# def compare_geotiff_size(image1_path, image2_path):\n#     # Open the first GeoTIFF image\n#     with rasterio.open(image1_path) as src1:\n#         width1 = src1.width\n#         height1 = src1.height\n#         shape1 = (height1, width1)\n#         num_pixels1 = width1 * height1\n\n#     # Open the second GeoTIFF image\n#     with rasterio.open(image2_path) as src2:\n#         width2 = src2.width\n#         height2 = src2.height\n#         shape2 = (height2, width2)\n#         num_pixels2 = width2 * height2\n\n#     # Compare the shapes and number of pixels\n#     if shape1 == shape2 and num_pixels1 == num_pixels2:\n#         print(\"The two GeoTIFF images have the same shape and number of pixels.\")\n#         print(f\"Shape: {shape1}, Number of Pixels: {num_pixels1}\")\n#         return True\n#     else:\n#         print(\"The two GeoTIFF images do not have the same shape and/or number of pixels.\")\n#         print(f\"Image 1 - Shape: {shape1}, Number of Pixels: {num_pixels1}\")\n#         print(f\"Image 2 - Shape: {shape2}, Number of Pixels: {num_pixels2}\")\n#         return False\n\n# # Example usage\n# image1_path = '/kaggle/input/lst-12/EarthEngineExports/Benin/LST_MonthlyMean_2000_02.tif'\n# image2_path = '/kaggle/input/ndvi-month/NDVI_Images/Benin/NDVI_Benin_2000_02.tif'\n\n# compare_geotiff_size(image1_path, image2_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T12:17:07.657764Z","iopub.execute_input":"2025-02-13T12:17:07.658116Z","iopub.status.idle":"2025-02-13T12:17:08.577086Z","shell.execute_reply.started":"2025-02-13T12:17:07.658089Z","shell.execute_reply":"2025-02-13T12:17:08.576189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import rasterio\n\n# def compare_geotiff_size(image_paths):\n#     \"\"\"\n#     Compare the size (shape and number of pixels) of multiple GeoTIFF images.\n\n#     Args:\n#         image_paths (list): List of paths to the GeoTIFF images.\n\n#     Returns:\n#         bool: True if all images have the same shape and number of pixels, False otherwise.\n#     \"\"\"\n#     shapes = []\n#     num_pixels = []\n\n#     # Loop through each image and extract its shape and number of pixels\n#     for path in image_paths:\n#         with rasterio.open(path) as src:\n#             width = src.width\n#             height = src.height\n#             shape = (height, width)\n#             shapes.append(shape)\n#             num_pixels.append(width * height)\n\n#     # Check if all shapes and pixel counts are the same\n#     if all(s == shapes[0] for s in shapes) and all(p == num_pixels[0] for p in num_pixels):\n#         print(\"All GeoTIFF images have the same shape and number of pixels.\")\n#         print(f\"Shape: {shapes[0]}, Number of Pixels: {num_pixels[0]}\")\n#         return True\n#     else:\n#         print(\"The GeoTIFF images do not have the same shape and/or number of pixels.\")\n#         for i, (shape, pixels) in enumerate(zip(shapes, num_pixels)):\n#             print(f\"Image {i + 1} - Shape: {shape}, Number of Pixels: {pixels}\")\n#         return False\n\n# # Example usage\n# image_paths = [\n#     '/kaggle/input/gldas-soil-moisture-monthly/gldas_monthly/Benin_SoilMoisture_Monthly/Benin_SoilMoisture_2000-01.tif',\n#     '/kaggle/input/lst-12/EarthEngineExports/Benin/LST_MonthlyMean_2000_02.tif',\n#     '/kaggle/input/ndvi-month/NDVI_Images/Benin/NDVI_Benin_2000_02.tif',\n#     '/kaggle/input/spi-chirps/Benin/Benin_SPI_2000_01.tif'\n# ]\n\n# compare_geotiff_size(image_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T12:26:12.953457Z","iopub.execute_input":"2025-02-13T12:26:12.953785Z","iopub.status.idle":"2025-02-13T12:26:14.086454Z","shell.execute_reply.started":"2025-02-13T12:26:12.953757Z","shell.execute_reply":"2025-02-13T12:26:14.085491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import glob\n# import rasterio\n# from datetime import datetime\n\n# # Define the base paths for each dataset\n# base_paths = {\n#     \"NDVI\": \"/kaggle/input/ndvi-month/NDVI_Images\",\n#     \"SoilMoisture\": \"/kaggle/input/soil-moisture/soil_moisture_masked\",\n#     \"SPI\": {\n#         \"Chad\": \"/kaggle/input/spi-sudan-chad-niger/downloaded_files/Chad_files\",\n#         \"Niger\": \"/kaggle/input/spi-sudan-chad-niger/downloaded_files/Niger_files\",\n#         \"Sudan\": \"/kaggle/input/spi-sudan-chad-niger/downloaded_files/Sudan_files\",\n#         \"Others\": \"/kaggle/input/spi-chirps\"\n#     },\n#     \"LST\": {\n#         \"Benin\": \"/kaggle/input/lst-12/EarthEngineExports/Benin\",\n#         \"Burkina_Faso\": \"/kaggle/input/lst-12/EarthEngineExports/Burkina_Faso\",\n#         \"Mauritania\": \"/kaggle/input/lst-12/EarthEngineExports/Mauritania\",\n#         \"Mali\": \"/kaggle/input/lst-12/EarthEngineExports/Mali\",\n#         \"Togo\": \"/kaggle/input/lst-12/EarthEngineExports/Togo\",\n#         \"Chad\": \"/kaggle/input/lst-12/EarthEngineExports/Chad\",\n#         \"Nigeria\": \"/kaggle/input/lst-12/EarthEngineExports/Nigeria\",\n#         \"Niger\": \"/kaggle/input/lst-12/EarthEngineExports/Niger\",\n#         \"Ghana\": \"/kaggle/input/lst-12/EarthEngineExports/Ghana\",\n#         \"Guinea\": \"/kaggle/input/lst-22/EarthEngineExports/Guinea\",\n#         \"Gambia,_The\": \"/kaggle/input/lst-22/EarthEngineExports/Gambia,_The\",\n#         \"Senegal\": \"/kaggle/input/lst-22/EarthEngineExports/Senegal\",\n#         \"Sierra_Leone\": \"/kaggle/input/lst-22/EarthEngineExports/Sierra_Leone\",\n#         \"Liberia\": \"/kaggle/input/lst-22/EarthEngineExports/Liberia\",\n#         \"Guinea-Bissau\": \"/kaggle/input/lst-22/EarthEngineExports/Guinea-Bissau\",\n#         \"Sudan\": \"/kaggle/input/lst-22/EarthEngineExports/Sudan\",\n#         \"Cote_dIvoire\": \"/kaggle/input/lst-22/EarthEngineExports/cote_divoire\"\n#     }\n# }\n\n# # List of countries\n# countries = [\n#     \"Benin\", \"Burkina_Faso\", \"Chad\", \"Cote_dIvoire\", \"Gambia,_The\", \"Ghana\",\n#     \"Guinea\", \"Guinea-Bissau\", \"Liberia\", \"Mali\", \"Mauritania\", \"Niger\",\n#     \"Nigeria\", \"Senegal\", \"Sierra_Leone\", \"Sudan\", \"Togo\"\n# ]\n\n# # Define the time range (2000-02 to 2023-12)\n# start_date = datetime(2000, 2, 1)\n# end_date = datetime(2023, 12, 31)\n\n# def extract_date_from_filename(filename, dataset):\n#     \"\"\"Extract the date from the filename based on the dataset.\"\"\"\n#     if dataset == \"NDVI\":\n#         # Example: NDVI_Benin_2000_02.tif\n#         date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n#         return datetime.strptime(date_str, \"%Y_%m\")\n#     elif dataset == \"SoilMoisture\":\n#         # Example: GLDAS_SoilMoisture_Benin_2000_01.tif\n#         date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n#         return datetime.strptime(date_str, \"%Y_%m\")\n#     elif dataset == \"SPI\":\n#         if \"SPI_Chad_\" in filename or \"SPI_Niger_\" in filename or \"SPI_Sudan_\" in filename:\n#             # Example: SPI_Chad_2000-01.tif\n#             date_str = filename.split(\"_\")[-1].split(\".\")[0]\n#             return datetime.strptime(date_str, \"%Y-%m\")\n#         else:\n#             # Example: Benin_SPI_2000_01.tif\n#             date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n#             return datetime.strptime(date_str, \"%Y_%m\")\n#     elif dataset == \"LST\":\n#         # Example: LST_MonthlyMean_2000_02.tif or LST_Gambia, The_2000_02.tif\n#         date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n#         return datetime.strptime(date_str, \"%Y_%m\")\n#     else:\n#         raise ValueError(f\"Unknown dataset: {dataset}\")\n\n# def get_file_paths(country, dataset):\n#     \"\"\"Generate file paths for a given country and dataset.\"\"\"\n#     if dataset == \"NDVI\":\n#         return glob.glob(os.path.join(base_paths[\"NDVI\"], country, f\"NDVI_{country}_*.tif\"))\n#     elif dataset == \"SoilMoisture\":\n#         return glob.glob(os.path.join(base_paths[\"SoilMoisture\"], country, f\"GLDAS_SoilMoisture_{country}_*.tif\"))\n#     elif dataset == \"SPI\":\n#         if country in [\"Chad\", \"Niger\", \"Sudan\"]:\n#             return glob.glob(os.path.join(base_paths[\"SPI\"][country], f\"SPI_{country}_*.tif\"))\n#         else:\n#             return glob.glob(os.path.join(base_paths[\"SPI\"][\"Others\"], country, f\"{country}_SPI_*.tif\"))\n#     elif dataset == \"LST\":\n#         return glob.glob(os.path.join(base_paths[\"LST\"][country], f\"LST_*.tif\"))\n#     else:\n#         raise ValueError(f\"Unknown dataset: {dataset}\")\n\n# def filter_files_by_date(files, dataset):\n#     \"\"\"Filter files to include only those within the specified date range.\"\"\"\n#     filtered_files = []\n#     for file in files:\n#         try:\n#             date = extract_date_from_filename(os.path.basename(file), dataset)\n#             if start_date <= date <= end_date:\n#                 filtered_files.append(file)\n#         except ValueError as e:\n#             print(f\"Skipping file {file} due to date parsing error: {e}\")\n#     return sorted(filtered_files)\n\n# def compare_shapes(file_paths):\n#     \"\"\"Compare the shapes of all files in the given list of paths.\"\"\"\n#     if not file_paths:\n#         return None  # Return None if no files are found\n#     shapes = []\n#     for path in file_paths:\n#         with rasterio.open(path) as src:\n#             shapes.append((src.height, src.width))\n#     if all(s == shapes[0] for s in shapes):\n#         return shapes[0]\n#     else:\n#         return None\n\n# def check_country_data(country):\n#     \"\"\"Check the compatibility of NDVI, LST, SPI-1, and soil moisture data for a given country.\"\"\"\n#     datasets = [\"NDVI\", \"SoilMoisture\", \"SPI\", \"LST\"]\n#     file_paths = {dataset: filter_files_by_date(get_file_paths(country, dataset), dataset) for dataset in datasets}\n\n#     # Check if all datasets have the same number of files\n#     num_files = {dataset: len(paths) for dataset, paths in file_paths.items()}\n#     if len(set(num_files.values())) != 1:\n#         print(f\"Warning: {country} has mismatched number of files across datasets: {num_files}\")\n#         return False\n\n#     # Compare shapes of all files\n#     shapes = {dataset: compare_shapes(paths) for dataset, paths in file_paths.items()}\n#     if None in shapes.values():\n#         print(f\"Warning: {country} has missing files for some datasets. Skipping shape comparison.\")\n#         return False\n#     elif all(s == shapes[\"NDVI\"] for s in shapes.values()):\n#         print(f\"{country}: All datasets have the same shape: {shapes['NDVI']}\")\n#         return True\n#     else:\n#         print(f\"{country}: Mismatched shapes across datasets: {shapes}\")\n#         return False\n\n# # Main script\n# for country in countries:\n#     check_country_data(country)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T23:58:05.418479Z","iopub.execute_input":"2025-02-16T23:58:05.418880Z","iopub.status.idle":"2025-02-17T00:01:14.026026Z","shell.execute_reply.started":"2025-02-16T23:58:05.418847Z","shell.execute_reply":"2025-02-17T00:01:14.024126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import glob\n# import rasterio\n# from datetime import datetime\n\n# # Define the base paths for each dataset\n# base_paths = {\n#     \"NDVI\": \"/kaggle/input/ndvi-month/NDVI_Images\",\n#     \"SoilMoisture\": \"/kaggle/input/soil-moisture/soil_moisture_masked\",\n#     \"SPI\": {\n#         \"Chad\": \"/kaggle/input/spi-sudan-chad-niger/downloaded_files/Chad_files\",\n#         \"Niger\": \"/kaggle/input/spi-sudan-chad-niger/downloaded_files/Niger_files\",\n#         \"Sudan\": \"/kaggle/input/spi-sudan-chad-niger/downloaded_files/Sudan_files\",\n#         \"Others\": \"/kaggle/input/spi-chirps\"\n#     },\n#     \"LST\": {\n#         \"Benin\": \"/kaggle/input/lst-12/EarthEngineExports/Benin\",\n#         \"Burkina_Faso\": \"/kaggle/input/lst-12/EarthEngineExports/Burkina_Faso\",\n#         \"Mauritania\": \"/kaggle/input/lst-12/EarthEngineExports/Mauritania\",\n#         \"Mali\": \"/kaggle/input/lst-12/EarthEngineExports/Mali\",\n#         \"Togo\": \"/kaggle/input/lst-12/EarthEngineExports/Togo\",\n#         \"Chad\": \"/kaggle/input/lst-12/EarthEngineExports/Chad\",\n#         \"Nigeria\": \"/kaggle/input/lst-12/EarthEngineExports/Nigeria\",\n#         \"Niger\": \"/kaggle/input/lst-12/EarthEngineExports/Niger\",\n#         \"Ghana\": \"/kaggle/input/lst-12/EarthEngineExports/Ghana\",\n#         \"Guinea\": \"/kaggle/input/lst-22/EarthEngineExports/Guinea\",\n#         \"Gambia,_The\": \"/kaggle/input/lst-22/EarthEngineExports/Gambia,_The\",\n#         \"Senegal\": \"/kaggle/input/lst-22/EarthEngineExports/Senegal\",\n#         \"Sierra_Leone\": \"/kaggle/input/lst-22/EarthEngineExports/Sierra_Leone\",\n#         \"Liberia\": \"/kaggle/input/lst-22/EarthEngineExports/Liberia\",\n#         \"Guinea-Bissau\": \"/kaggle/input/lst-22/EarthEngineExports/Guinea-Bissau\",\n#         \"Sudan\": \"/kaggle/input/lst-22/EarthEngineExports/Sudan\",\n#         \"Cote_dIvoire\": \"/kaggle/input/lst-22/EarthEngineExports/cote_divoire\"\n#     }\n# }\n\n# # List of countries\n# countries = [\n#     \"Benin\", \"Burkina_Faso\", \"Chad\", \"Cote_dIvoire\", \"Gambia,_The\", \"Ghana\",\n#     \"Guinea\", \"Guinea-Bissau\", \"Liberia\", \"Mali\", \"Mauritania\", \"Niger\",\n#     \"Nigeria\", \"Senegal\", \"Sierra_Leone\", \"Sudan\", \"Togo\"\n# ]\n\n# # Define the time range (2000-02 to 2023-12)\n# start_date = datetime(2000, 2, 1)\n# end_date = datetime(2023, 12, 31)\n\n# def extract_date_from_filename(filename, dataset):\n#     \"\"\"Extract the date from the filename based on the dataset.\"\"\"\n#     if dataset == \"NDVI\":\n#         # Example: NDVI_Benin_2000_02.tif\n#         date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n#         return datetime.strptime(date_str, \"%Y_%m\")\n#     elif dataset == \"SoilMoisture\":\n#         # Example: GLDAS_SoilMoisture_Benin_2000_01.tif\n#         date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n#         return datetime.strptime(date_str, \"%Y_%m\")\n#     elif dataset == \"SPI\":\n#         if \"SPI_Chad_\" in filename or \"SPI_Niger_\" in filename or \"SPI_Sudan_\" in filename:\n#             # Example: SPI_Chad_2000-01.tif\n#             date_str = filename.split(\"_\")[-1].split(\".\")[0]\n#             return datetime.strptime(date_str, \"%Y-%m\")\n#         else:\n#             # Example: Benin_SPI_2000_01.tif\n#             date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n#             return datetime.strptime(date_str, \"%Y_%m\")\n#     elif dataset == \"LST\":\n#         # Example: LST_MonthlyMean_2000_02.tif or LST_Gambia, The_2000_02.tif\n#         date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n#         return datetime.strptime(date_str, \"%Y_%m\")\n#     else:\n#         raise ValueError(f\"Unknown dataset: {dataset}\")\n\n# def get_file_paths(country, dataset):\n#     \"\"\"Generate file paths for a given country and dataset.\"\"\"\n#     if dataset == \"NDVI\":\n#         return glob.glob(os.path.join(base_paths[\"NDVI\"], country, f\"NDVI_{country}_*.tif\"))\n#     elif dataset == \"SoilMoisture\":\n#         if country == \"Gambia,_The\":\n#             # Handle Gambia_The soil moisture path\n#             return glob.glob(os.path.join(base_paths[\"SoilMoisture\"], \"Gambia_The\", f\"GLDAS_SoilMoisture_Gambia_The_*.tif\"))\n#         else:\n#             return glob.glob(os.path.join(base_paths[\"SoilMoisture\"], country, f\"GLDAS_SoilMoisture_{country}_*.tif\"))\n#     elif dataset == \"SPI\":\n#         if country in [\"Chad\", \"Niger\", \"Sudan\"]:\n#             return glob.glob(os.path.join(base_paths[\"SPI\"][country], f\"SPI_{country}_*.tif\"))\n#         else:\n#             return glob.glob(os.path.join(base_paths[\"SPI\"][\"Others\"], country, f\"{country}_SPI_*.tif\"))\n#     elif dataset == \"LST\":\n#         return glob.glob(os.path.join(base_paths[\"LST\"][country], f\"LST_*.tif\"))\n#     else:\n#         raise ValueError(f\"Unknown dataset: {dataset}\")\n\n# def filter_files_by_date(files, dataset):\n#     \"\"\"Filter files to include only those within the specified date range.\"\"\"\n#     filtered_files = []\n#     for file in files:\n#         try:\n#             date = extract_date_from_filename(os.path.basename(file), dataset)\n#             if start_date <= date <= end_date:\n#                 filtered_files.append(file)\n#         except ValueError as e:\n#             print(f\"Skipping file {file} due to date parsing error: {e}\")\n#     return sorted(filtered_files)\n\n# def get_common_months(file_paths):\n#     \"\"\"Extract common months across all datasets for a country.\"\"\"\n#     months = {}\n#     for dataset, paths in file_paths.items():\n#         months[dataset] = set()\n#         for path in paths:\n#             try:\n#                 date = extract_date_from_filename(os.path.basename(path), dataset)\n#                 months[dataset].add((date.year, date.month))\n#             except ValueError as e:\n#                 print(f\"Skipping file {path} due to date parsing error: {e}\")\n#     # Find intersection of all months\n#     common_months = set.intersection(*months.values())\n#     return sorted(common_months)\n\n# def filter_files_by_common_months(file_paths, common_months):\n#     \"\"\"Filter files to include only those with common months.\"\"\"\n#     filtered_paths = {}\n#     for dataset, paths in file_paths.items():\n#         filtered_paths[dataset] = []\n#         for path in paths:\n#             try:\n#                 date = extract_date_from_filename(os.path.basename(path), dataset)\n#                 if (date.year, date.month) in common_months:\n#                     filtered_paths[dataset].append(path)\n#             except ValueError as e:\n#                 print(f\"Skipping file {path} due to date parsing error: {e}\")\n#     return filtered_paths\n\n# def compare_shapes(file_paths):\n#     \"\"\"Compare the shapes of all files in the given list of paths.\"\"\"\n#     if not file_paths:\n#         return None  # Return None if no files are found\n#     shapes = []\n#     for path in file_paths:\n#         with rasterio.open(path) as src:\n#             shapes.append((src.height, src.width))\n#     if all(s == shapes[0] for s in shapes):\n#         return shapes[0]\n#     else:\n#         return None\n\n# def check_country_data(country):\n#     \"\"\"Check the compatibility of NDVI, LST, SPI-1, and soil moisture data for a given country.\"\"\"\n#     datasets = [\"NDVI\", \"SoilMoisture\", \"SPI\", \"LST\"]\n#     file_paths = {dataset: filter_files_by_date(get_file_paths(country, dataset), dataset) for dataset in datasets}\n\n#     # Get common months across all datasets\n#     common_months = get_common_months(file_paths)\n#     if not common_months:\n#         print(f\"Warning: {country} has no common months across datasets. Skipping shape comparison.\")\n#         return False\n\n#     # Filter files to include only common months\n#     file_paths = filter_files_by_common_months(file_paths, common_months)\n\n#     # Compare shapes of all files\n#     shapes = {dataset: compare_shapes(paths) for dataset, paths in file_paths.items()}\n#     if None in shapes.values():\n#         print(f\"Warning: {country} has missing files for some datasets. Skipping shape comparison.\")\n#         return False\n#     elif all(s == shapes[\"NDVI\"] for s in shapes.values()):\n#         print(f\"{country}: All datasets have the same shape: {shapes['NDVI']}\")\n#         return True\n#     else:\n#         print(f\"{country}: Mismatched shapes across datasets: {shapes}\")\n#         return False\n\n# # Main script\n# for country in countries:\n#     check_country_data(country)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport rasterio\nfrom datetime import datetime\nfrom scipy.interpolate import interp1d\nimport zipfile\nimport shutil  # For deleting folders\n\n# Define the base paths for each dataset\nbase_paths = {\n    \"NDVI\": \"/kaggle/input/ndvi-month/NDVI_Images\",\n    \"SoilMoisture\": \"/kaggle/input/soil-moisture/soil_moisture_masked\",\n    \"SPI\": {\n        \"Chad\": \"/kaggle/input/spi-sudan-chad-niger/downloaded_files/Chad_files\",\n        \"Niger\": \"/kaggle/input/spi-sudan-chad-niger/downloaded_files/Niger_files\",\n        \"Sudan\": \"/kaggle/input/spi-sudan-chad-niger/downloaded_files/Sudan_files\",\n        \"Others\": \"/kaggle/input/spi-chirps\"\n    },\n    \"LST\": {\n        \"Benin\": \"/kaggle/input/lst-12/EarthEngineExports/Benin\",\n        \"Burkina_Faso\": \"/kaggle/input/lst-12/EarthEngineExports/Burkina_Faso\",\n        \"Mauritania\": \"/kaggle/input/lst-12/EarthEngineExports/Mauritania\",\n        \"Mali\": \"/kaggle/input/lst-12/EarthEngineExports/Mali\",\n        \"Togo\": \"/kaggle/input/lst-12/EarthEngineExports/Togo\",\n        \"Chad\": \"/kaggle/input/lst-12/EarthEngineExports/Chad\",\n        \"Nigeria\": \"/kaggle/input/lst-12/EarthEngineExports/Nigeria\",\n        \"Niger\": \"/kaggle/input/lst-12/EarthEngineExports/Niger\",\n        \"Ghana\": \"/kaggle/input/lst-12/EarthEngineExports/Ghana\",\n        \"Guinea\": \"/kaggle/input/lst-22/EarthEngineExports/Guinea\",\n        \"Gambia,_The\": \"/kaggle/input/lst-22/EarthEngineExports/Gambia,_The\",\n        \"Senegal\": \"/kaggle/input/lst-22/EarthEngineExports/Senegal\",\n        \"Sierra_Leone\": \"/kaggle/input/lst-22/EarthEngineExports/Sierra_Leone\",\n        \"Liberia\": \"/kaggle/input/lst-22/EarthEngineExports/Liberia\",\n        \"Guinea-Bissau\": \"/kaggle/input/lst-22/EarthEngineExports/Guinea-Bissau\",\n        \"Sudan\": \"/kaggle/input/lst-22/EarthEngineExports/Sudan\",\n        \"Cote_dIvoire\": \"/kaggle/input/lst-22/EarthEngineExports/cote_divoire\"\n    }\n}\n\n# List of countries\ncountries = [\n    \"Benin\", \"Burkina_Faso\", \"Chad\", \"Cote_dIvoire\", \"Gambia,_The\", \"Ghana\",\n    \"Guinea\", \"Guinea-Bissau\", \"Liberia\"\n]\n# Define the time range (2000-02 to 2023-12)\nstart_date = datetime(2000, 2, 1)\nend_date = datetime(2023, 12, 31)\n\n# Output directory for country folders\noutput_dir = \"/kaggle/working/time_series\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Tile size for processing large rasters\ntile_size = 256  # Process rasters in 256x256 tiles\n\ndef extract_date_from_filename(filename, dataset):\n    \"\"\"Extract the date from the filename based on the dataset.\"\"\"\n    if dataset == \"NDVI\":\n        # Example: NDVI_Benin_2000_02.tif\n        date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n        return datetime.strptime(date_str, \"%Y_%m\")\n    elif dataset == \"SoilMoisture\":\n        # Example: GLDAS_SoilMoisture_Benin_2000_01.tif\n        date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n        return datetime.strptime(date_str, \"%Y_%m\")\n    elif dataset == \"SPI\":\n        if \"SPI_Chad_\" in filename or \"SPI_Niger_\" in filename or \"SPI_Sudan_\" in filename:\n            # Example: SPI_Chad_2000-01.tif\n            date_str = filename.split(\"_\")[-1].split(\".\")[0]\n            return datetime.strptime(date_str, \"%Y-%m\")\n        else:\n            # Example: Benin_SPI_2000_01.tif\n            date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n            return datetime.strptime(date_str, \"%Y_%m\")\n    elif dataset == \"LST\":\n        # Example: LST_MonthlyMean_2000_02.tif or LST_Gambia, The_2000_02.tif\n        date_str = filename.split(\"_\")[-2] + \"_\" + filename.split(\"_\")[-1].split(\".\")[0]\n        return datetime.strptime(date_str, \"%Y_%m\")\n    else:\n        raise ValueError(f\"Unknown dataset: {dataset}\")\n\ndef get_file_paths(country, dataset):\n    \"\"\"Generate file paths for a given country and dataset.\"\"\"\n    if dataset == \"NDVI\":\n        return glob.glob(os.path.join(base_paths[\"NDVI\"], country, f\"NDVI_{country}_*.tif\"))\n    elif dataset == \"SoilMoisture\":\n        if country == \"Gambia,_The\":\n            # Handle Gambia_The soil moisture path\n            return glob.glob(os.path.join(base_paths[\"SoilMoisture\"], \"Gambia_The\", f\"GLDAS_SoilMoisture_Gambia_The_*.tif\"))\n        else:\n            return glob.glob(os.path.join(base_paths[\"SoilMoisture\"], country, f\"GLDAS_SoilMoisture_{country}_*.tif\"))\n    elif dataset == \"SPI\":\n        if country in [\"Chad\", \"Niger\", \"Sudan\"]:\n            return glob.glob(os.path.join(base_paths[\"SPI\"][country], f\"SPI_{country}_*.tif\"))\n        else:\n            return glob.glob(os.path.join(base_paths[\"SPI\"][\"Others\"], country, f\"{country}_SPI_*.tif\"))\n    elif dataset == \"LST\":\n        return glob.glob(os.path.join(base_paths[\"LST\"][country], f\"LST_*.tif\"))\n    else:\n        raise ValueError(f\"Unknown dataset: {dataset}\")\n\ndef load_raster_tile(src, row_start, col_start, tile_size):\n    \"\"\"Load a tile from a raster.\"\"\"\n    row_end = min(row_start + tile_size, src.height)\n    col_end = min(col_start + tile_size, src.width)\n    return src.read(1, window=((row_start, row_end), (col_start, col_end)))\n\ndef process_tile(country, datasets, tile_row, tile_col, tile_size):\n    \"\"\"Process a single tile for a country, excluding pixels outside the country bounds.\"\"\"\n    time_series_tile = {}\n\n    # Load the mask from the Soil Moisture dataset\n    soil_moisture_files = get_file_paths(country, \"SoilMoisture\")\n    if not soil_moisture_files:\n        print(f\"Warning: No Soil Moisture files found for {country}.\")\n        return None\n\n    with rasterio.open(soil_moisture_files[0]) as src:\n        mask = src.read(2)  # Load the mask (Band 2)\n        valid_pixels = mask == 255  # Pixels inside the country bounds (assuming mask uses 255 for valid pixels)\n\n    # Crop the mask to the current tile\n    tile_height = min(tile_size, mask.shape[0] - tile_row)\n    tile_width = min(tile_size, mask.shape[1] - tile_col)\n    tile_mask = valid_pixels[tile_row:tile_row + tile_height, tile_col:tile_col + tile_width]\n\n    # Only process pixels inside the mask\n    if not np.any(tile_mask):\n        print(f\"Skipping tile ({tile_row}, {tile_col}) for {country}: No valid pixels in the mask.\")\n        return None\n\n    for dataset in datasets:\n        file_paths = get_file_paths(country, dataset)\n        if not file_paths:\n            print(f\"Warning: No files found for {country} in dataset {dataset}.\")\n            continue\n\n        # Initialize an empty array to store the tile's time series\n        date_range = pd.date_range(start=start_date, end=end_date, freq=\"MS\")\n        tile_data = np.full((len(date_range), tile_height, tile_width), np.nan)\n\n        for i, date in enumerate(date_range):\n            for path in file_paths:\n                file_date = extract_date_from_filename(os.path.basename(path), dataset)\n                if file_date == date:\n                    with rasterio.open(path) as src:\n                        if dataset == \"SoilMoisture\":\n                            # For Soil Moisture, use Band 1\n                            tile = src.read(1, window=((tile_row, tile_row + tile_height), (tile_col, tile_col + tile_width)))\n                        else:\n                            # For other datasets, use Band 1 and replace No-Data values (0) with NaN\n                            tile = src.read(1, window=((tile_row, tile_row + tile_height), (tile_col, tile_col + tile_width)))\n                            tile[tile == 0] = np.nan\n                        tile_data[i] = tile\n                    break\n\n        if dataset == \"SoilMoisture\":\n            # Interpolate missing months for Soil Moisture\n            for row in range(tile_height):\n                for col in range(tile_width):\n                    if tile_mask[row, col]:  # Only interpolate valid pixels\n                        time_series = tile_data[:, row, col]\n                        valid_mask = ~np.isnan(time_series)\n                        if np.sum(valid_mask) > 1:  # Require at least 2 valid points for interpolation\n                            interp_func = interp1d(\n                                date_range[valid_mask].astype(np.int64),  # Convert dates to numeric\n                                time_series[valid_mask],\n                                kind=\"linear\",\n                                fill_value=\"extrapolate\"\n                            )\n                            tile_data[:, row, col] = interp_func(date_range.astype(np.int64))\n\n        # Apply the mask to exclude pixels outside the country bounds\n        tile_data[:, ~tile_mask] = np.nan\n\n        time_series_tile[dataset] = tile_data\n\n    return time_series_tile\n\ndef save_tile(country, tile_row, tile_col, tile_data, country_dir):\n    \"\"\"Save a tile's data to disk.\"\"\"\n    tile_path = os.path.join(country_dir, f\"{country}_tile_{tile_row}_{tile_col}.npz\")\n    np.savez_compressed(tile_path, **tile_data)\n    return tile_path\n\ndef combine_npz_files(country, country_dir, original_height, original_width):\n    \"\"\"Combine all .npz files for a country into a single .npz file, preserving the original shape.\"\"\"\n    # Find all .npz files for the country\n    npz_files = glob.glob(os.path.join(country_dir, f\"{country}_tile_*.npz\"))\n    if not npz_files:\n        print(f\"No .npz files found for {country}.\")\n        return\n\n    # Initialize arrays to store the full raster for each dataset\n    date_range = pd.date_range(start=start_date, end=end_date, freq=\"MS\")\n    full_data = {\n        \"NDVI\": np.full((len(date_range), original_height, original_width), np.nan),\n        \"SoilMoisture\": np.full((len(date_range), original_height, original_width), np.nan),\n        \"SPI\": np.full((len(date_range), original_height, original_width), np.nan),\n        \"LST\": np.full((len(date_range), original_height, original_width), np.nan),\n    }\n\n    # Load and place each tile in its correct position\n    for npz_file in npz_files:\n        with np.load(npz_file) as data:\n            # Extract tile position from the filename\n            tile_name = os.path.basename(npz_file)\n            tile_row = int(tile_name.split(\"_\")[-2])\n            tile_col = int(tile_name.split(\"_\")[-1].split(\".\")[0])\n\n            # Place the tile in the full raster\n            for dataset in full_data.keys():\n                if dataset in data:\n                    tile_height, tile_width = data[dataset].shape[1], data[dataset].shape[2]\n                    full_data[dataset][\n                        :,\n                        tile_row : tile_row + tile_height,\n                        tile_col : tile_col + tile_width,\n                    ] = data[dataset]\n\n    # Save the combined data to a single .npz file\n    combined_npz_path = os.path.join(country_dir, f\"{country}_combined.npz\")\n    np.savez_compressed(combined_npz_path, **full_data)\n\n    print(f\"Combined {len(npz_files)} files for {country} into {combined_npz_path}\")\n\n    # Delete the individual tile .npz files\n    for npz_file in npz_files:\n        os.remove(npz_file)\n    print(f\"Deleted individual tile .npz files for {country}.\")\n\n    return combined_npz_path\n\ndef zip_country_folder(country, country_dir):\n    \"\"\"Zip the country's folder.\"\"\"\n    zip_path = os.path.join(output_dir, f\"{country}.zip\")\n    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED, compresslevel=9) as zipf:\n        for root, _, files in os.walk(country_dir):\n            for file in files:\n                file_path = os.path.join(root, file)\n                zipf.write(file_path, os.path.relpath(file_path, country_dir))\n    print(f\"Zipped {country_dir} into {zip_path}\")\n\n    # Delete the country folder after zipping\n    shutil.rmtree(country_dir)\n    print(f\"Deleted folder {country_dir}.\")\n\n# Process all countries\nfor country in countries:\n    print(f\"Processing {country}...\")\n    # Create a folder for the country\n    country_dir = os.path.join(output_dir, country)\n    os.makedirs(country_dir, exist_ok=True)\n\n    # Process the country in tiles\n    datasets = [\"NDVI\", \"SoilMoisture\", \"SPI\", \"LST\"]\n    file_paths = get_file_paths(country, datasets[0])\n    if not file_paths:\n        print(f\"Warning: No files found for {country} in dataset {datasets[0]}.\")\n        continue\n\n    with rasterio.open(file_paths[0]) as src:\n        height, width = src.shape\n\n    for tile_row in range(0, height, tile_size):\n        for tile_col in range(0, width, tile_size):\n            print(f\"Processing tile ({tile_row}, {tile_col}) for {country}...\")\n            tile_data = process_tile(country, datasets, tile_row, tile_col, tile_size)\n            if tile_data is not None:\n                save_tile(country, tile_row, tile_col, tile_data, country_dir)\n\n    # Combine all .npz files for the country\n    combined_npz_path = combine_npz_files(country, country_dir, height, width)\n\n    # Zip the country's folder\n    zip_country_folder(country, country_dir)\n\nprint(\"All countries processed and zipped individually!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T01:08:22.837138Z","iopub.execute_input":"2025-02-27T01:08:22.837524Z","iopub.status.idle":"2025-02-27T01:09:05.768149Z","shell.execute_reply.started":"2025-02-27T01:08:22.837489Z","shell.execute_reply":"2025-02-27T01:09:05.766955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import zipfile\n# import os\n\n# # Path to the zipped file\n# zip_path = \"/kaggle/working/time_series/Gambia,_The.zip\"\n\n# # Directory to extract the .npz file\n# extract_dir = \"/kaggle/working/extracted\"\n# os.makedirs(extract_dir, exist_ok=True)\n\n# # Unzip the file\n# with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n#     zip_ref.extractall(extract_dir)\n#     print(f\"Unzipped {zip_path} to {extract_dir}\")\n\n# # Find the .npz file in the extracted directory\n# npz_files = [f for f in os.listdir(extract_dir) if f.endswith(\".npz\")]\n\n# if not npz_files:\n#     print(\"No .npz files found in the extracted directory.\")\n# else:\n#     # Load the first .npz file (assuming only one per country)\n#     npz_path = os.path.join(extract_dir, npz_files[0])\n#     with np.load(npz_path) as data:\n#         print(f\"Loaded {npz_files[0]} with the following datasets:\")\n        \n#         # Print available dataset keys and their shapes\n#         for key in data.files:\n#             print(f\"{key}: shape {data[key].shape}\")\n        \n#         # Example: Accessing NDVI data (adjust this based on available keys)\n#         if \"NDVI\" in data:\n#             ndvi_series = data[\"NDVI\"]\n#             print(f\"\\nNDVI Time Series Shape: {ndvi_series.shape}\")\n#             print(\"Sample NDVI data (first time step):\")\n#             print(ndvi_series[0])  # Print the first time step\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T01:09:45.103231Z","iopub.execute_input":"2025-02-27T01:09:45.103740Z","iopub.status.idle":"2025-02-27T01:09:46.233200Z","shell.execute_reply.started":"2025-02-27T01:09:45.103710Z","shell.execute_reply":"2025-02-27T01:09:46.232219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n\n# # Path to the .npz file\n# npz_path = \"/kaggle/working/extracted/Gambia,_The_combined.npz\"\n\n# def verify_time_series(npz_path):\n#     \"\"\"Verify the time series data in the .npz file.\"\"\"\n#     # Load the .npz file\n#     with np.load(npz_path) as data:\n#         print(\"Verifying time series for Gambia,_The...\")\n#         for dataset in [\"NDVI\", \"SoilMoisture\", \"SPI\", \"LST\"]:\n#             if dataset not in data:\n#                 print(f\"Warning: Dataset {dataset} not found in the .npz file.\")\n#                 continue\n\n#             # Extract the dataset\n#             dataset_data = data[dataset]\n\n#             # Check for NaN values\n#             nan_count = np.isnan(dataset_data).sum()\n#             print(f\"{dataset} - NaN values: {nan_count}\")\n\n#             # Compute mean, max, and min (ignoring NaN values)\n#             mean_value = np.nanmean(dataset_data)\n#             max_value = np.nanmax(dataset_data)\n#             min_value = np.nanmin(dataset_data)\n\n#             print(f\"{dataset} - Mean: {mean_value}, Max: {max_value}, Min: {min_value}\")\n\n# # Verify the time series\n# verify_time_series(npz_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T00:15:39.035141Z","iopub.execute_input":"2025-02-27T00:15:39.035516Z","iopub.status.idle":"2025-02-27T00:15:40.297597Z","shell.execute_reply.started":"2025-02-27T00:15:39.035468Z","shell.execute_reply":"2025-02-27T00:15:40.296536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shutil\n# import os\n\n# working_dir = \"/kaggle/working\"\n\n# # Remove all files in kaggle/working\n# for filename in os.listdir(working_dir):\n#     file_path = os.path.join(working_dir, filename)\n#     try:\n#         if os.path.isfile(file_path) or os.path.islink(file_path):\n#             os.unlink(file_path)  # Remove files and symlinks\n#         elif os.path.isdir(file_path):\n#             shutil.rmtree(file_path)  # Remove directories\n#     except Exception as e:\n#         print(f\"Failed to delete {file_path}: {e}\")\n\n# print(\"Cleared /kaggle/working/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T05:59:19.477997Z","iopub.execute_input":"2025-02-26T05:59:19.478369Z","iopub.status.idle":"2025-02-26T05:59:19.487428Z","shell.execute_reply.started":"2025-02-26T05:59:19.478338Z","shell.execute_reply":"2025-02-26T05:59:19.486214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import rasterio\n# from rasterio.plot import show\n# import matplotlib.pyplot as plt\n\n# # Path to the .npz file\n# npz_path = \"/kaggle/working/extracted/Gambia,_The_combined.npz\"\n\n# def visualize_time_step(npz_path, time_step=0):\n#     \"\"\"Visualize a single time step for each dataset in the .npz file.\"\"\"\n#     # Load the .npz file\n#     with np.load(npz_path) as data:\n#         print(\"Visualizing time step:\", time_step)\n\n#         # Plot each dataset\n#         for dataset in [\"NDVI\", \"SoilMoisture\", \"SPI\", \"LST\"]:\n#             if dataset not in data:\n#                 print(f\"Warning: Dataset {dataset} not found in the .npz file.\")\n#                 continue\n\n#             # Extract the time step\n#             dataset_data = data[dataset][time_step]\n\n#             # Plot the data\n#             plt.figure(figsize=(10, 6))\n#             plt.imshow(dataset_data, cmap='viridis', vmin=np.nanmin(dataset_data), vmax=np.nanmax(dataset_data))\n#             plt.colorbar(label='Value')\n#             plt.title(f\"{dataset} - Time Step {time_step}\")\n#             plt.show()\n\n#             # Plot NaN values\n#             plt.figure(figsize=(10, 6))\n#             plt.imshow(np.isnan(dataset_data), cmap='gray')\n#             plt.colorbar(label='NaN Values')\n#             plt.title(f\"{dataset} - NaN Values (Time Step {time_step})\")\n#             plt.show()\n\n# # Visualize the first time step (index 0)\n# visualize_time_step(npz_path, time_step=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T01:09:51.403805Z","iopub.execute_input":"2025-02-27T01:09:51.404154Z","iopub.status.idle":"2025-02-27T01:09:54.676707Z","shell.execute_reply.started":"2025-02-27T01:09:51.404125Z","shell.execute_reply":"2025-02-27T01:09:54.675522Z"}},"outputs":[],"execution_count":null}]}